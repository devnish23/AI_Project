=~=~=~=~=~=~=~=~=~=~=~= PuTTY log 2025.05.20 16:46:25 =~=~=~=~=~=~=~=~=~=~=~=
login as: infradm
infradm@192.168.56.121's password: 
Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-60-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/pro

 System information as of Tue May 20 08:46:39 AM UTC 2025

  System load:             0.23
  Usage of /:              66.1% of 11.21GB
  Memory usage:            6%
  Swap usage:              0%
  Processes:               118
  Users logged in:         0
  IPv4 address for enp0s3: 10.0.2.15
  IPv6 address for enp0s3: fd00::a00:27ff:fe46:9480

 * Strictly confined Kubernetes makes edge and IoT secure. Learn how MicroK8s
   just raised the bar for easy, resilient and secure K8s cluster deployment.

   https://ubuntu.com/engage/secure-kubernetes-at-the-edge

Expanded Security Maintenance for Applications is not enabled.

61 updates can be applied immediately.
To see these additional updates run: apt list --upgradable

Enable ESM Apps to receive additional future security updates.
See https://ubuntu.com/esm or run: sudo pro status


Last login: Tue May 20 08:01:05 2025 from 192.168.56.2
[?2004h]0;infradm@kmaster: ~infradm@kmaster:~$ [K]0;infradm@kmaster: ~infradm@kmaster:~$ sudo su -
[?2004l[sudo] password for infradm: 
[?2004h]0;root@kmaster: ~root@kmaster:~# ip a
[?2004l1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host noprefixroute 
       valid_lft forever preferred_lft forever
2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 08:00:27:46:94:80 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic enp0s3
       valid_lft 85228sec preferred_lft 85228sec
    inet6 fd00::a00:27ff:fe46:9480/64 scope global dynamic mngtmpaddr noprefixroute 
       valid_lft 86258sec preferred_lft 14258sec
    inet6 fe80::a00:27ff:fe46:9480/64 scope link 
       valid_lft forever preferred_lft forever
3: enp0s8: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
    link/ether 08:00:27:25:51:d4 brd ff:ff:ff:ff:ff:ff
    inet 192.168.56.121/24 metric 100 brd 192.168.56.255 scope global dynamic enp0s8
       valid_lft 327sec preferred_lft 327sec
    inet6 fe80::a00:27ff:fe25:51d4/64 scope link 
       valid_lft forever preferred_lft forever
[?2004h]0;root@kmaster: ~root@kmaster:~# kubc[Ke
kubeadm  kubectl  kubelet  
]0;root@kmaster: ~root@kmaster:~# kube
kubeadm  kubectl  kubelet  
]0;root@kmaster: ~root@kmaster:~# kubectl get pods
[?2004lThe connection to the server 192.168.56.121:6443 was refused - did you specify the right host or port?
[?2004h]0;root@kmaster: ~root@kmaster:~# kubeadm 
[?2004l

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ KUBEADM                                                  â”‚
    â”‚ Easily bootstrap a secure Kubernetes cluster             â”‚
    â”‚                                                          â”‚
    â”‚ Please give us feedback at:                              â”‚
    â”‚ https://github.com/kubernetes/kubeadm/issues             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example usage:

    Create a two-machine cluster with one control-plane node
    (which controls the cluster), and one worker node
    (where your workloads, like Pods and Deployments run).

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ On the first machine:                                    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ control-plane# kubeadm init                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ On the second machine:                                   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ worker# kubeadm join <arguments-returned-from-init>      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    You can then repeat the second step on as many other machines as you like.

Usage:
  kubeadm [command]

Available Commands:
  certs       Commands related to handling kubernetes certificates
  completion  Output shell completion code for the specified shell (bash or zsh)
  config      Manage configuration for a kubeadm cluster persisted in a ConfigMap in the cluster
  help        Help about any command
  init        Run this command in order to set up the Kubernetes control plane
  join        Run this on any machine you wish to join an existing cluster
  kubeconfig  Kubeconfig file utilities
  reset       Performs a best effort revert of changes made to this host by 'kubeadm init' or 'kubeadm join'
  token       Manage bootstrap tokens
  upgrade     Upgrade your cluster smoothly to a newer version with this command
  version     Print the version of kubeadm

Flags:
      --add-dir-header           If true, adds the file directory to the header of the log messages
  -h, --help                     help for kubeadm
      --log-file string          If non-empty, use this log file (no effect when -logtostderr=true)
      --log-file-max-size uint   Defines the maximum size a log file can grow to (no effect when -logtostderr=true). Unit is megabytes. If the value is 0, the maximum file size is unlimited. (default 1800)
      --one-output               If true, only write logs to their native severity level (vs also writing to each lower severity level; no effect when -logtostderr=true)
      --rootfs string            [EXPERIMENTAL] The path to the 'real' host root filesystem.
      --skip-headers             If true, avoid header prefixes in the log messages
      --skip-log-headers         If true, avoid headers when opening log files (no effect when -logtostderr=true)
  -v, --v Level                  number for the log level verbosity

Additional help topics:
  kubeadm alpha      Kubeadm experimental sub-commands

Use "kubeadm [command] --help" for more information about a command.
[?2004h]0;root@kmaster: ~root@kmaster:~# [7msudo kubeadm reset -f[27m[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Csudo kubeadm reset -f
[?2004l[reset] Reading configuration from the cluster...
[reset] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
W0520 08:48:00.249470    2219 reset.go:120] [reset] Unable to fetch the kubeadm-config ConfigMap from cluster: failed to get config map: Get "https://192.168.56.121:6443/api/v1/namespaces/kube-system/configmaps/kubeadm-config?timeout=10s": dial tcp 192.168.56.121:6443: connect: connection refused
[preflight] Running pre-flight checks
W0520 08:48:00.249618    2219 removeetcdmember.go:106] [reset] No kubeadm config, using etcd pod spec to get data directory
[reset] Deleted contents of the etcd data directory: /var/lib/etcd
[reset] Stopping the kubelet service
[reset] Unmounting mounted directories in "/var/lib/kubelet"

W0520 08:48:34.102473    2219 cleanupnode.go:99] [reset] Failed to remove containers: [failed to stop running pod 411fa2ce1b840588551d4be7ea61046c23b27f0bac7ff73ff8debe6fbe90682a: output: E0520 08:48:11.864128    2320 remote_runtime.go:222] "StopPodSandbox from runtime service failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" podSandboxID="411fa2ce1b840588551d4be7ea61046c23b27f0bac7ff73ff8debe6fbe90682a"
time="2025-05-20T08:48:11Z" level=fatal msg="stopping the pod sandbox \"411fa2ce1b840588551d4be7ea61046c23b27f0bac7ff73ff8debe6fbe90682a\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
: exit status 1, failed to stop running pod 2eef2efef03751794086aa1747f4a43799293ced5e1091ba4bf8ee2d53757353: output: E0520 08:48:22.434362    2433 remote_runtime.go:222] "StopPodSandbox from runtime service failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" podSandboxID="2eef2efef03751794086aa1747f4a43799293ced5e1091ba4bf8ee2d53757353"
time="2025-05-20T08:48:22Z" level=fatal msg="stopping the pod sandbox \"2eef2efef03751794086aa1747f4a43799293ced5e1091ba4bf8ee2d53757353\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
: exit status 1, failed to stop running pod ac3f02655ba6963f5cd53b3ef5b58517d6dd16cf838e72afbe664c83188cd405: output: E0520 08:48:33.069009    2547 remote_runtime.go:222] "StopPodSandbox from runtime service failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" podSandboxID="ac3f02655ba6963f5cd53b3ef5b58517d6dd16cf838e72afbe664c83188cd405"
time="2025-05-20T08:48:33Z" level=fatal msg="stopping the pod sandbox \"ac3f02655ba6963f5cd53b3ef5b58517d6dd16cf838e72afbe664c83188cd405\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
: exit status 1]
[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki]
[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]

The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d

The reset process does not reset or clean up iptables rules or IPVS tables.
If you wish to reset iptables, you must do so manually by using the "iptables" command.

If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)
to reset your system's IPVS tables.

The reset process does not clean your kubeconfig files and you must remove them manually.
Please, check the contents of the $HOME/.kube/config file.
[?2004h]0;root@kmaster: ~root@kmaster:~# exit
[?2004llogout
[?2004h]0;infradm@kmaster: ~infradm@kmaster:~$ exit
[?2004llogout
